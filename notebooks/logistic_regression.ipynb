{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417c12aa",
   "metadata": {},
   "source": [
    "# Logistic Regression Analysis\n",
    "\n",
    "**Logistic Regression** is a classification algorithm used to predict the probability of a categorical dependent variable. In this notebook, we use it to estimate the likelihood of heart attack risk based on clinical parameters.\n",
    "\n",
    "### üî¨ Mathematical Approach:\n",
    "Unlike linear regression, we use the **Sigmoid Function** to map predicted values to probabilities between 0 and 1. \n",
    "We will leverage `scipy.optimize` and `sklearn` to find the best-fitting model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dde4e730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientific environment for Logistic Regression is ready.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# Specific tools for Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, jaccard_score\n",
    "\n",
    "print(\"Scientific environment for Logistic Regression is ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8766e5",
   "metadata": {},
   "source": [
    "## üìÇ Data Loading & Structure Inspection\n",
    "\n",
    "In this step, we re-initialize the dataset for the **Logistic Regression** pipeline. Before training, we inspect the statistical distribution of features to ensure they are suitable for a probabilistic model. \n",
    "\n",
    "Key focuses:\n",
    "* **Scale of values**: Identifying the range for each clinical metric.\n",
    "* **Target balance**: Confirming the distribution of the `output` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0216566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Dataset Preview ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Descriptive Statistics ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp      trtbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg    thalachh        exng     oldpeak         slp         caa  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "            thall      output  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Features available: 14\n",
      "Columns: ['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall', 'output']\n",
      "\n",
      " Data Integrity Check: No missing values found.\n"
     ]
    }
   ],
   "source": [
    "# Load the heart dataset\n",
    "df = pd.read_csv(\"../data/heart.csv\")\n",
    "\n",
    "# 1. Peek at the first few rows\n",
    "print(\"--- Dataset Preview ---\")\n",
    "display(df.head())\n",
    "\n",
    "# 2. Statistical breakdown\n",
    "print(\"\\n--- Descriptive Statistics ---\")\n",
    "display(df.describe())\n",
    "\n",
    "# 3. Quick Column check for Feature Selection\n",
    "print(f\"\\nTotal Features available: {len(df.columns)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Optional: Check for missing values (always a plus in Git)\n",
    "if df.isnull().sum().sum() == 0:\n",
    "    print(\"\\n Data Integrity Check: No missing values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce79ec1",
   "metadata": {},
   "source": [
    "## üõ† Data Structuring & Type Casting\n",
    "\n",
    "To ensure compatibility with high-performance numerical libraries like **NumPy** and **SciPy**, we perform the following:\n",
    "1. **Feature Selection**: Explicitly defining our clinical predictors.\n",
    "2. **Type Casting**: Ensuring the target variable `output` is in integer format for binary classification.\n",
    "3. **Matrix Conversion**: Converting DataFrames into NumPy arrays ($X$ and $y$) for efficient mathematical operations during the optimization of the Logistic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e13058c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix X shape: (303, 13)\n",
      "Target vector y shape: (303,)\n",
      "\n",
      "First 5 entries of the target (y): [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Re-ordering and selecting relevant columns\n",
    "df = df[['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', 'thalachh',\n",
    "         'exng', 'oldpeak', 'slp', 'caa', 'thall', 'output']]\n",
    "\n",
    "# Ensure the target is of integer type\n",
    "df[\"output\"] = df['output'].astype(int)\n",
    "\n",
    "# Extract features into a NumPy array\n",
    "X = np.asarray(df[['age', 'sex', 'cp', 'trtbps', 'chol', 'fbs', 'restecg', \n",
    "                   'thalachh', 'exng', 'oldpeak', 'slp', 'caa', 'thall']])\n",
    "\n",
    "# Extract target into a NumPy array\n",
    "y = np.asarray(df[\"output\"])\n",
    "\n",
    "# Quick verification of the conversion\n",
    "print(f\"Feature matrix X shape: {X.shape}\")\n",
    "print(f\"Target vector y shape: {y.shape}\")\n",
    "print(\"\\nFirst 5 entries of the target (y):\", y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb93847",
   "metadata": {},
   "source": [
    "## ‚öñÔ∏è Feature Standardization\n",
    "\n",
    "For **Logistic Regression**, standardization is essential to ensure that the optimization algorithm (like `liblinear` or `lbfgs`) converges efficiently. \n",
    "\n",
    "By applying `StandardScaler`, we transform our features to ensure they all have a similar influence on the model coefficients. This prevents features with large magnitudes from causing numerical instability during the calculation of the **Sigmoid function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "714e98d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled successfully.\n",
      "Sample of standardized data (First 5 rows):\n",
      "[[ 0.9521966   0.68100522  1.97312292  0.76395577 -0.25633371  2.394438\n",
      "  -1.00583187  0.01544279 -0.69663055  1.08733806 -2.27457861 -0.71442887\n",
      "  -2.14887271]\n",
      " [-1.91531289  0.68100522  1.00257707 -0.09273778  0.07219949 -0.41763453\n",
      "   0.89896224  1.63347147 -0.69663055  2.12257273 -2.27457861 -0.71442887\n",
      "  -0.51292188]\n",
      " [-1.47415758 -1.46841752  0.03203122 -0.09273778 -0.81677269 -0.41763453\n",
      "  -1.00583187  0.97751389 -0.69663055  0.31091206  0.97635214 -0.71442887\n",
      "  -0.51292188]\n",
      " [ 0.18017482  0.68100522  0.03203122 -0.66386682 -0.19835726 -0.41763453\n",
      "   0.89896224  1.23989692 -0.69663055 -0.20670527  0.97635214 -0.71442887\n",
      "  -0.51292188]\n",
      " [ 0.29046364 -1.46841752 -0.93851463 -0.66386682  2.08204965 -0.41763453\n",
      "   0.89896224  0.58393935  1.43548113 -0.37924438  0.97635214 -0.71442887\n",
      "  -0.51292188]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Initialize and fit the scaler\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "\n",
    "# Transform the feature matrix\n",
    "X = scaler.transform(X)\n",
    "\n",
    "# Display the first 5 rows of scaled features\n",
    "print(\"Features scaled successfully.\")\n",
    "print(\"Sample of standardized data (First 5 rows):\")\n",
    "print(X[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de66906",
   "metadata": {},
   "source": [
    "## üß™ Train/Test Split\n",
    "\n",
    "To ensure our **Logistic Regression** model generalizes well to new, unseen patients, we split our standardized dataset:\n",
    "* **Training Set (80%)**: Used to optimize the model coefficients.\n",
    "* **Testing Set (20%)**: Used to evaluate the model's predictive power and calculate metrics like Log Loss.\n",
    "\n",
    "We use `random_state=42` to ensure that our results can be replicated by other researchers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f0cabfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Split Summary:\n",
      "Training set: 242 samples\n",
      "Testing set:  61 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reporting the split sizes\n",
    "print(\"Dataset Split Summary:\")\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set:  {X_test.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45261254",
   "metadata": {},
   "source": [
    "## ü§ñ Logistic Regression Implementation\n",
    "\n",
    "We initialize the model using the **Liblinear** solver, which is highly effective for binary classification on smaller datasets. \n",
    "\n",
    "* **Regularization (C=0.1)**: We use a smaller C value to increase regularization strength, which helps the model generalize better and prevents it from relying too heavily on any single feature.\n",
    "* **Probability Estimates**: Beyond simple binary classification (0 or 1), we calculate the probability of each class. This is essential for clinical risk assessment where the confidence of a prediction matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88b81bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training Complete.\n",
      "\n",
      "First 10 Predicted Labels: [0 1 1 0 1 1 1 0 0 0]\n",
      "First 10 Actual Labels:    [0 0 1 0 1 1 1 0 0 1]\n",
      "\n",
      "--- Probability Breakdown (First 5 patients) ---\n",
      "Patient 1: Risk Probability = 15.29%\n",
      "Patient 2: Risk Probability = 64.53%\n",
      "Patient 3: Risk Probability = 77.43%\n",
      "Patient 4: Risk Probability = 6.65%\n",
      "Patient 5: Risk Probability = 90.42%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. Initialize and Train\n",
    "# C is the inverse of regularization strength; smaller values specify stronger regularization.\n",
    "lr_model = LogisticRegression(C=0.1, solver='liblinear').fit(X_train, y_train)\n",
    "\n",
    "# 2. Predict Class Labels\n",
    "y_hat = lr_model.predict(X_test)\n",
    "\n",
    "# 3. Predict Probabilities\n",
    "# Returns [Prob of Class 0, Prob of Class 1]\n",
    "y_hat_prob = lr_model.predict_proba(X_test)\n",
    "\n",
    "# --- Visualizing Results ---\n",
    "print(f\"Model Training Complete.\")\n",
    "print(f\"\\nFirst 10 Predicted Labels: {y_hat[0:10]}\")\n",
    "print(f\"First 10 Actual Labels:    {y_test[0:10].flatten()}\") # Flatten for clean display\n",
    "\n",
    "print(\"\\n--- Probability Breakdown (First 5 patients) ---\")\n",
    "# Displaying probability of 'High Risk' (Class 1)\n",
    "for i in range(5):\n",
    "    print(f\"Patient {i+1}: Risk Probability = {y_hat_prob[i][1]:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec48590e",
   "metadata": {},
   "source": [
    "## üìä Model Evaluation: Beyond Simple Accuracy\n",
    "\n",
    "To truly understand how our **Logistic Regression** model performs, we use three distinct metrics:\n",
    "1. **Jaccard Score**: Measures the similarity between the predicted labels and the true labels. We calculate this for both 'Low Risk' (0) and 'High Risk' (1) classes.\n",
    "2. **Precision & Recall**: Crucial for medical diagnosis. \n",
    "    * *Precision*: When we predict a heart attack, how often are we right?\n",
    "    * *Recall*: Out of all actual heart attacks, how many did we successfully catch?\n",
    "3. **F1-Score**: The harmonic mean of Precision and Recall, providing a balanced view of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92622b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Scores:\n",
      "   - Class 0 (Low Risk):  0.7576\n",
      "   - Class 1 (High Risk): 0.7778\n",
      "-----------------------------------\n",
      "Overall Accuracy: 0.8689\n",
      "-----------------------------------\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Low Risk       0.86      0.86      0.86        29\n",
      "   High Risk       0.88      0.88      0.88        32\n",
      "\n",
      "    accuracy                           0.87        61\n",
      "   macro avg       0.87      0.87      0.87        61\n",
      "weighted avg       0.87      0.87      0.87        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import jaccard_score, classification_report, accuracy_score\n",
    "\n",
    "# 1. Jaccard Similarity Score\n",
    "j_score_0 = jaccard_score(y_test, y_hat, pos_label=0)\n",
    "j_score_1 = jaccard_score(y_test, y_hat, pos_label=1)\n",
    "\n",
    "print(\"Jaccard Similarity Scores:\")\n",
    "print(f\"   - Class 0 (Low Risk):  {j_score_0:.4f}\")\n",
    "print(f\"   - Class 1 (High Risk): {j_score_1:.4f}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# 2. Accuracy\n",
    "acc = accuracy_score(y_test, y_hat)\n",
    "print(f\"Overall Accuracy: {acc:.4f}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "# 3. Classification Report\n",
    "print(\"Detailed Classification Report:\")\n",
    "print(classification_report(y_test, y_hat, target_names=['Low Risk', 'High Risk']))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
